{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob # use your path\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import scipy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Copyright Mathieu Blondel December 2011\n",
    "# # License: BSD 3 clause\n",
    "\n",
    "# import numpy as np\n",
    "# import pylab as pl\n",
    "\n",
    "# from sklearn.base import BaseEstimator\n",
    "# from sklearn.utils import check_random_state\n",
    "# from sklearn.cluster import MiniBatchKMeans\n",
    "# from sklearn.cluster import KMeans as KMeansGood\n",
    "# from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances\n",
    "# from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "# ##############################################################################\n",
    "# # Generate sample data\n",
    "# np.random.seed(0)\n",
    "\n",
    "# batch_size = 45\n",
    "# centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "# n_clusters = len(centers)\n",
    "# X, labels_true = make_blobs(n_samples=1200, centers=centers, cluster_std=0.3)\n",
    "\n",
    "# class KMeans(BaseEstimator):\n",
    "\n",
    "#     def __init__(self, k, max_iter=100, random_state=0, tol=1e-4):\n",
    "#         self.k = k\n",
    "#         self.max_iter = max_iter\n",
    "#         self.random_state = random_state\n",
    "#         self.tol = tol\n",
    "\n",
    "#     def _e_step(self, X):\n",
    "#         self.labels_ = euclidean_distances(X, self.cluster_centers_,\n",
    "#                                      squared=True).argmin(axis=1)\n",
    "\n",
    "#     def _average(self, X):\n",
    "#         return X.mean(axis=0)\n",
    "\n",
    "#     def _m_step(self, X):\n",
    "#         X_center = None\n",
    "#         for center_id in range(self.k):\n",
    "#             center_mask = self.labels_ == center_id\n",
    "#             if not np.any(center_mask):\n",
    "#                 # The centroid of empty clusters is set to the center of\n",
    "#                 # everything\n",
    "#                 if X_center is None:\n",
    "#                     X_center = self._average(X)\n",
    "#                 self.cluster_centers_[center_id] = X_center\n",
    "#             else:\n",
    "#                 self.cluster_centers_[center_id] = \\\n",
    "#                     self._average(X[center_mask])\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         n_samples = X.shape[0]\n",
    "#         vdata = np.mean(np.var(X, 0))\n",
    "\n",
    "#         random_state = check_random_state(self.random_state)\n",
    "#         self.labels_ = random_state.permutation(n_samples)[:self.k]\n",
    "#         self.cluster_centers_ = X[self.labels_]\n",
    "\n",
    "#         for i in xrange(self.max_iter):\n",
    "#             centers_old = self.cluster_centers_.copy()\n",
    "\n",
    "#             self._e_step(X)\n",
    "#             self._m_step(X)\n",
    "\n",
    "#             if np.sum((centers_old - self.cluster_centers_) ** 2) < self.tol * vdata:\n",
    "#                 break\n",
    "\n",
    "#         return self\n",
    "\n",
    "# class KMedians(KMeans):\n",
    "\n",
    "#     def _e_step(self, X):\n",
    "#         self.labels_ = manhattan_distances(X, self.cluster_centers_).argmin(axis=1)\n",
    "\n",
    "#     def _average(self, X):\n",
    "#         return np.median(X, axis=0)\n",
    "\n",
    "# class FuzzyKMeans(KMeans):\n",
    "\n",
    "#     def __init__(self, k, m=2, max_iter=100, random_state=0, tol=1e-4):\n",
    "#         \"\"\"\n",
    "#         m > 1: fuzzy-ness parameter\n",
    "#         The closer to m is to 1, the closter to hard kmeans.\n",
    "#         The bigger m, the fuzzier (converge to the global cluster).\n",
    "#         \"\"\"\n",
    "#         self.k = k\n",
    "#         assert m > 1\n",
    "#         self.m = m\n",
    "#         self.max_iter = max_iter\n",
    "#         self.random_state = random_state\n",
    "#         self.tol = tol\n",
    "\n",
    "#     def _e_step(self, X):\n",
    "#         D = 1.0 / euclidean_distances(X, self.cluster_centers_, squared=True)\n",
    "#         D **= 1.0 / (self.m - 1)\n",
    "#         D /= np.sum(D, axis=1)[:, np.newaxis]\n",
    "#         # shape: n_samples x k\n",
    "#         self.fuzzy_labels_ = D\n",
    "#         self.labels_ = self.fuzzy_labels_.argmax(axis=1)\n",
    "\n",
    "#     def _m_step(self, X):\n",
    "#         weights = self.fuzzy_labels_ ** self.m\n",
    "#         # shape: n_clusters x n_features\n",
    "#         self.cluster_centers_ = np.dot(X.T, weights).T\n",
    "#         self.cluster_centers_ /= weights.sum(axis=0)[:, np.newaxis]\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         n_samples, n_features = X.shape\n",
    "#         vdata = np.mean(np.var(X, 0))\n",
    "\n",
    "#         random_state = check_random_state(self.random_state)\n",
    "#         self.fuzzy_labels_ = random_state.rand(n_samples, self.k)\n",
    "#         self.fuzzy_labels_ /= self.fuzzy_labels_.sum(axis=1)[:, np.newaxis]\n",
    "#         self._m_step(X)\n",
    "\n",
    "#         for i in xrange(self.max_iter):\n",
    "#             centers_old = self.cluster_centers_.copy()\n",
    "\n",
    "#             self._e_step(X)\n",
    "#             self._m_step(X)\n",
    "\n",
    "#             if np.sum((centers_old - self.cluster_centers_) ** 2) < self.tol * vdata:\n",
    "#                 break\n",
    "\n",
    "#         return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5026_air_weekday_out.csv\n",
      "9019_air_weekday_out.csv\n",
      "8142_air_weekday_out.csv\n",
      "5852_air_weekday_out.csv\n",
      "4193_air_weekday_out.csv\n",
      "7531_air_weekday_out.csv\n",
      "9922_air_weekday_out.csv\n",
      "4957_air_weekday_out.csv\n",
      "2974_air_weekday_out.csv\n",
      "5785_air_weekday_out.csv\n",
      "8419_air_weekday_out.csv\n",
      "2004_air_weekday_out.csv\n",
      "898_air_weekday_out.csv\n",
      "26_air_weekday_out.csv\n",
      "2769_air_weekday_out.csv\n",
      "2156_air_weekday_out.csv\n",
      "6941_air_weekday_out.csv\n",
      "9343_air_weekday_out.csv\n",
      "7794_air_weekday_out.csv\n",
      "9356_air_weekday_out.csv\n",
      "370_air_weekday_out.csv\n",
      "4874_air_weekday_out.csv\n",
      "6910_air_weekday_out.csv\n",
      "7901_air_weekday_out.csv\n",
      "2575_air_weekday_out.csv\n",
      "2864_air_weekday_out.csv\n",
      "8967_air_weekday_out.csv"
     ]
    }
   ],
   "source": [
    "def preparedata(file1,zh):\n",
    "    data2 = pd.DataFrame()\n",
    "    for i in file1:\n",
    "        print i\n",
    "        data = pd.read_csv(i)\n",
    "        data.drop(['Date','Houseid'], axis=1, inplace=True)\n",
    "        data = data.fillna(0)\n",
    "        data1 = pd.DataFrame(data.iloc[zh])\n",
    "        data2 = pd.concat([data1,data2],axis=1)\n",
    "#     print data2, \"data2\"\n",
    "    return data2\n",
    "        \n",
    "def kmeansdata(data2):\n",
    "    da2 = data2.transpose()\n",
    "    k_mea= KMeans(init='k-means++', n_clusters=47)\n",
    "#     k_mea= KMeans(k=47)\n",
    "    barc = k_mea.fit(da2)\n",
    "    fdf2 = pd.DataFrame(barc.cluster_centers_)\n",
    "    fdf3 = fdf2.transpose()\n",
    "    print fdf3, \"fdf3 inside function\"\n",
    "    return fdf3\n",
    "\n",
    "def takeabs(fdf3,actual):\n",
    "    delta_t = 60\n",
    "    jh = 1440/delta_t\n",
    "    ans = []\n",
    "    for restf in fdf3.columns:\n",
    "        a = fdf3[restf]\n",
    "        for shift in range(jh):\n",
    "            ans.append(scipy.absolute(scipy.roll(a,shift*delta_t) - actual).sum())\n",
    "    indexloc = ans.index(min(ans))\n",
    "    pstar = indexloc/jh\n",
    "    jstar= indexloc%jh\n",
    "    adf=fdf3[pstar]\n",
    "    adff=np.roll(adf,jstar)\n",
    "    adff1=pd.Series(adff)\n",
    "    print adff1,\"pd.Series(adff)\"\n",
    "    return adff1\n",
    "\n",
    "# def takeit():\n",
    "#     bestpat = takeabs(kmpat,actual)\n",
    "#     actual = actual.subtract(bestpat)\n",
    "#     bestpatmp = mergdat(bestpatmp,bestpat)\n",
    "#     return bestpatmp\n",
    "\n",
    "def mergdat(mergpat,bestpat):\n",
    "    bestpat = pd.concat([mergpat,bestpat], axis=0)\n",
    "    return bestpat\n",
    "\n",
    "endit = 7200\n",
    "datastat = 0\n",
    "for startit in range(0,14400,7200):\n",
    "    testf = pd.read_csv(\"26__weekday_out.csv\", skiprows=startit , nrows=7200)\n",
    "    actual1 = testf.iloc[:,7]\n",
    "    actual2 = pd.DataFrame()\n",
    "    words = ['air','dryer']\n",
    "# words = ['air','dryer','furnace','lights_plugs','refrigerator']\n",
    "    final_pat = pd.DataFrame()\n",
    "    for  i in words:\n",
    "        ghj = '*_'+i+'_weekday_out.csv'\n",
    "        allFiles = glob.glob(ghj)\n",
    "        data3 = pd.DataFrame()\n",
    "        for ite in range(datastat,datastat+5):\n",
    "            data4 = preparedata(allFiles,ite)\n",
    "            data3 = pd.concat([data3,data4], axis=1)\n",
    "            print data3, \"data3\"\n",
    "        kmpat = kmeansdata(data3)\n",
    "        bestpatmp = pd.DataFrame()\n",
    "        if (words.index(i)>0):\n",
    "            actual1 = actual2\n",
    "        for readit in range(0,7200,1440):\n",
    "            bestpat = takeabs(kmpat,np.array(actual1.iloc[readit:readit+1440]))\n",
    "            actual = actual1.iloc[readit:readit+1440]\n",
    "            actual = actual.subtract(bestpat)\n",
    "            bestpatmp = mergdat(bestpatmp,bestpat)\n",
    "            actual2 = mergdat(actual2,actual)\n",
    "        datastat = datastat+5\n",
    "        final_pat = pd.concat([final_pat,bestpatmp], axis=1)\n",
    "        print final_pat, \"final_pat\"\n",
    "    final_pat.to_csv('solution.csv', mode='a', index = False, index_label = False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# r1 = pd.read_csv(\"solution.csv\", header=-1)\n",
    "# r1.columns = [\"a\",\"b\"]\n",
    "# chel = pd.read_csv(\"26__weekday_out.csv\")\n",
    "# cnm = chel.iloc[0:2880,1]\n",
    "# ssreg = np.sum((cnm-r1.a)**2)\n",
    "# ssreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# deep = pd.read_csv('26_out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deep = actual1.iloc[readit:readit+1440]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "takeabs(kmpat,np.array(deep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmpat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for readit in range(0,7200,1440):\n",
    "    bestpat = takeabs(kmpat,pd.Series(list(actual1.iloc[readit:readit+1440])))\n",
    "    actual = actual1.iloc[readit:readit+1440]\n",
    "    actual = actual.subtract(bestpat)\n",
    "    bestpatmp = mergdat(bestpatmp,bestpat)\n",
    "    actual2 = mergdat(actual2,actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for startit in range(0,14400,7200):\n",
    "    testf = pd.read_csv(\"26__weekday_out.csv\",skiprows=startit,nrows=7200)\n",
    "    actual1 = testf.iloc[:,7]\n",
    "    for readit in range(startit,startit+7200,1440):\n",
    "        bestpat = actual1.iloc[readit:readit+1440]\n",
    "        print bestpat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for startit in range(0,14400,7200):\n",
    "    testf = pd.read_csv(\"26__weekday_out.csv\",skiprows=startit,nrows=7200)\n",
    "    actual = testf.iloc[:,7]\n",
    "#     print actual, 'actual',startit\n",
    "    for readit in range(0,7200,1440):\n",
    "        print actual.iloc[readit:readit+1440]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for startit in range(0,14400,7200):\n",
    "    i = i+1\n",
    "    for readit in range(0,7200,1440):\n",
    "        print readit, readit+1440,i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for readit in range(startit,startit+7200,1440):\n",
    "    print readit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print actual.iloc[0:8640]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for readit in range(startit,startit+7200,1440):\n",
    "        print actual.iloc[readit:readit+1440]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
